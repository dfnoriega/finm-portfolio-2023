{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sympy import Matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import skew, kurtosis, norm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from Functions import *\n",
    "\n",
    "\n",
    "def calculate_statistics(df, annualize_factor=12, VaR=0.05, CVaR=0.05):\n",
    "    '''\n",
    "    Calculates the mean, volatility, sharpe, skewness, kurtosis, VaR and CVaR of a dataframe\n",
    "    Returns a dataframe with values for each asset\n",
    "    '''\n",
    "    res={}\n",
    "    res_i={}\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype=='<M8[ns]':\n",
    "            pass\n",
    "        else:\n",
    "            res_i.update({'mean':np.mean(df[i])*annualize_factor})\n",
    "            res_i.update({'volatility':np.std(df[i])*(annualize_factor**(1/2))})\n",
    "            res_i.update({'sharpe':res_i['mean']/res_i['volatility']})\n",
    "            res_i.update({'skewness':skew(df[i])})\n",
    "            res_i.update({'kurtosis':kurtosis(df[i])})\n",
    "            res_i.update({'VaR':df[i].quantile(VaR)})\n",
    "            res_i.update({'CVaR':df[i][df[i]<df[i].quantile(CVaR)].mean()})\n",
    "            # res_i.update({'Max_Drawdown':maxDrawD(df[i])})\n",
    "            res.update({i:res_i})\n",
    "            res_i={}\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "def calculate_statistics_array(data, annualize_factor=12, VaR=0.05, CVaR=0.05):\n",
    "    '''\n",
    "    Calculates the mean, volatility and sharpe ratio of an array\n",
    "    Returns a dictionary with the 'mean', 'volatility' and 'sharpe' ratio of the array\n",
    "    '''\n",
    "    res_i={}\n",
    "    res_i.update({'mean':np.mean(data)*annualize_factor})\n",
    "    res_i.update({'volatility':np.std(data)*(annualize_factor**(1/2))})\n",
    "    res_i.update({'sharpe':res_i['mean']/res_i['volatility']})\n",
    "    res_i.update({'skewness':skew(data)})\n",
    "    res_i.update({'kurtosis':kurtosis(data)})\n",
    "    df=pd.DataFrame(data)\n",
    "    res_i.update({'VaR':df.quantile(VaR)})\n",
    "    res_i.update({'CVaR':df[df<df.quantile(CVaR)].mean()})\n",
    "    # res_i.update({'Max_Drawdown':maxDrawD(df[i])})\n",
    "    return res_i\n",
    "\n",
    "def tangency_portfolio(df):\n",
    "    '''\n",
    "    Calculates the weights of the tangency portfolio\n",
    "    Inputs: dataframe with column 0 being the date and the rest ([1:]) being the assets\n",
    "    Make sure df's first column (0) is the date, or anything that is not an asset\n",
    "    '''\n",
    "    stats=calculate_statistics(df)\n",
    "    assets=len(df.columns[1:])\n",
    "    mdf=Matrix(df.iloc[:,1:].cov())\n",
    "    vect1=Matrix([1]*assets)\n",
    "    mean=[]\n",
    "    for i in stats:\n",
    "        mean.append(stats[i]['mean'])\n",
    "    vectmean=Matrix(mean)\n",
    "    sigma_inv=mdf.inv()\n",
    "    wt=(1/((vect1.T@sigma_inv@vectmean)[0,0]))*(sigma_inv@vectmean)\n",
    "\n",
    "    tickers=[]\n",
    "    for i in stats:\n",
    "        tickers.append(i)\n",
    "    tan_port=pd.DataFrame()\n",
    "    tan_port['tickers']=tickers\n",
    "    tan_port['Tangent Weights']=0.0\n",
    "    for i in range(len(tan_port)):\n",
    "        tan_port.loc[i,'Tangent Weights']=float(round(wt[i], 6))\n",
    "    \n",
    "    tan_port.set_index('tickers', inplace=True,drop=True)\n",
    "\n",
    "    return tan_port\n",
    "    \n",
    "\n",
    "def correlation_heatmap(df):\n",
    "    '''\n",
    "    Plots a heatmap of the correlation matrix of a dataframe [1:]\n",
    "    '''\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    heatmap = sns.heatmap(df.iloc[:,1:].corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')\n",
    "    heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12)\n",
    "\n",
    "def calculate_market_statistics(df,regressor, annualize_factor=12):\n",
    "    '''\n",
    "    Calculates the alpha, beta, treynor ratio and information ratio of a dataframe for all non-date columns\n",
    "    Regressor is benchmark: e.g., SPY, Market\n",
    "    '''\n",
    "    res={}\n",
    "    res_i={}\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype=='<M8[ns]':\n",
    "            pass\n",
    "        else:\n",
    "            model=LinearRegression()\n",
    "            model.fit(np.array(regressor).reshape(-1,1),df[i])\n",
    "            alpha=model.intercept_*annualize_factor\n",
    "            beta=model.coef_[0]\n",
    "            res_i.update({'alpha':alpha})\n",
    "            res_i.update({'market_beta':beta})\n",
    "            res_i.update({'treynor_ratio':np.mean(df[i])*annualize_factor/beta})\n",
    "\n",
    "            residuals=np.array(df[i])-model.predict(np.array(regressor).reshape(-1,1))\n",
    "            res_i.update({'information_ratio':alpha/(np.std(residuals)*annualize_factor**(1/2))})\n",
    "\n",
    "            res.update({i:res_i})\n",
    "            res_i={}\n",
    "    return pd.DataFrame(res).transpose()\n",
    "\n",
    "def run_regression(df,regressors,annualize_factor=12):\n",
    "    '''\n",
    "    Runs a regression for all non-date columns in a dataframe\n",
    "    Regressors is a dataframe with the regressors as columns\n",
    "    Returns a dataframe with the alpha, betas, and r2 for each asset\n",
    "    '''\n",
    "    res={}\n",
    "    res_i={}\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype=='<M8[ns]':\n",
    "            pass\n",
    "        else:\n",
    "            model=LinearRegression()\n",
    "            model.fit(regressors,df[i])\n",
    "            alpha=model.intercept_*annualize_factor\n",
    "            betas=model.coef_\n",
    "            r2=model.score(regressors, df[i])\n",
    "            res_i.update({'alpha':alpha})\n",
    "            for ii in range(len(betas)):\n",
    "                res_i.update({'beta_'+str(regressors.columns[ii]):betas[ii]})\n",
    "            res_i.update({'r2':r2})\n",
    "            res.update({i:res_i})\n",
    "            res_i={}\n",
    "    \n",
    "    return pd.DataFrame(res).transpose()\n",
    "\n",
    "def prob(mu, sigma, h):\n",
    "    '''\n",
    "    Returns the probability of underperforming mu\n",
    "    over a period h. Make sure that mu and sigma are \n",
    "    from log returns.\n",
    "    '''\n",
    "    return norm.cdf(np.sqrt(h)*-mu/sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559895d2",
   "metadata": {},
   "source": [
    "# Midterm 2\n",
    "\n",
    "## FINM 36700 - 2023\n",
    "\n",
    "### UChicago Financial Mathematics\n",
    "\n",
    "* Mark Hendricks\n",
    "* hendricks@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cde8d3",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc273c1a",
   "metadata": {},
   "source": [
    "## Please note the following:\n",
    "\n",
    "Points\n",
    "* The exam is 100 points.\n",
    "* You have 120 minutes to complete the exam.\n",
    "* For every minute late you submit the exam, you will lose one point.\n",
    "\n",
    "\n",
    "Submission\n",
    "* You will upload your solution to the `Midterm 2` assignment on Canvas, where you downloaded this. (Be sure to **submit** on Canvas, not just **save** on Canvas.\n",
    "* Your submission should be readable, (the graders can understand your answers,) and it should **include all code used in your analysis in a file format that the code can be executed.** \n",
    "\n",
    "Rules\n",
    "* The exam is open-material, closed-communication.\n",
    "* You do not need to cite material from the course github repo--you are welcome to use the code posted there without citation.\n",
    "\n",
    "Advice\n",
    "* If you find any question to be unclear, state your interpretation and proceed. We will only answer questions of interpretation if there is a typo, error, etc.\n",
    "* The exam will be graded for partial credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624f27b1",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "**All data files are found in the class github repo, in the `data` folder.**\n",
    "\n",
    "This exam makes use of the following data files:\n",
    "* `midterm_2_data.xlsx`\n",
    "\n",
    "This file has sheets for...\n",
    "* `info` - names and descriptions of each factor\n",
    "* `factors (excess returns)` - excess returns on several factors\n",
    "* `portfolios (excess returns)` - excess returns on industry portfolios\n",
    "* `risk-free rate` - risk-free rates over time\n",
    "\n",
    "Note the data is **monthly** so any annualizations should use `12` months in a year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf6e066",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "| Problem | Points |\n",
    "|---------|--------|\n",
    "| 1       | 30     |\n",
    "| 2       | 35     |\n",
    "| 3       | 20     |\n",
    "| 4       | 15     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb2fc26",
   "metadata": {},
   "source": [
    "### Each numbered question is worth 5 points unless otherwise specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c2bdf",
   "metadata": {},
   "source": [
    "### Notation\n",
    "(Hidden LaTeX commands)\n",
    "\n",
    "$$\\newcommand{\\betamkt}{\\beta^{i,\\text{MKT}}}$$\n",
    "$$\\newcommand{\\betahml}{\\beta^{i,\\text{HML}}}$$\n",
    "$$\\newcommand{\\betaumd}{\\beta^{i,\\text{UMD}}}$$\n",
    "$$\\newcommand{\\Eri}{E\\left[\\tilde{r}^{i}\\right]}$$\n",
    "$$\\newcommand{\\Emkt}{E\\left[\\tilde{r}^{\\text{MKT}}\\right]}$$\n",
    "$$\\newcommand{\\Ehml}{E\\left[\\tilde{r}^{\\text{HML}}\\right]}$$\n",
    "$$\\newcommand{\\Eumd}{E\\left[\\tilde{r}^{\\text{UMD}}\\right]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81156e8f",
   "metadata": {},
   "source": [
    "# 1. Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf4bc8",
   "metadata": {},
   "source": [
    "#### No Data Needed\n",
    "\n",
    "These problems do not require any data file. Rather, analyze them conceptually. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2ec27",
   "metadata": {},
   "source": [
    "## 1.\n",
    "\n",
    "Suppose that we find a set of factors that perfectly hedge any asset. Will these factors work as a linear factor pricing model? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would only be the case if the correlations of the residuals were 0 and we had infinite assets. If it perfectly hedged any assets (assuming all errors were = 0) and you had infinite assets, it would also work as a pricing model. Given that infite assets is an unrealistic assumtion (so is perfect/corr of errors = 0; but assuming for a second), the factors would not necessarily work as a pricing model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7e3f3",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "If the Fama-French 3-factor model fit perfectly, would the Treynor ratio be equal for every asset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. If the CAPM fit perfectly, the Treynor would be equal. In the FF 3-factor model there are more factors! Consequently, assuming that the returns for the other factos are not equal to zero, a portion of the returns would be explained by the other 2 factors and the Treynor ratio would not necessarily be constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b269599",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "Suppose the CAPM fits perfectly. Then assets which have higher time-series r-squared metrics on the market factor will have higher Sharpe ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CAPM does not say anything about the r2 of the time-series metrics! Assets with a higher beta would have higher sharpe ratios, but capm fitting perfectly means alphas would be zero, nothing about the r2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa46a6",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "Based on the case, what are two ways DFA hopes to generate attractive returns for investors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through \"the value of sound academic research, and the ability of skilled traders to contribute to a fund's profits even when the investment was inherently passive.\"\n",
    "\n",
    "Maybe the question meant specifically, in which case it could be by using (1) the value factor, and the (2) size factor, in addition to the market factor. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8aede",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "We analyzed a strategy similar to \"AQR's Momentum Funds\" (mutual funds.) We found this implementation had much higher returns than the momentum factor of Fama French. What was a major drawback to this construction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That the correlation with the market was very high! The issue was going long only, as opposed to going long on high momentum, but short the negative momentum, which would mute the correlation with the market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e990eba3",
   "metadata": {},
   "source": [
    "## 6.\n",
    "\n",
    "From our analysis, momentum has had a negative mean return since 2009. Is this evidence against momentum as a pricing factor? Explain why this is a problem or why it is not a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not necessarily a problem! The correlation with other market factors is very small, and in cases negative, which offers significant diversification advantages even if returns are small, or slightly negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ce7d4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78ee6f4",
   "metadata": {},
   "source": [
    "# 2. Linear Factor Pricing Models (LFPMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef5b592",
   "metadata": {},
   "source": [
    "This problem tests the following LFPM:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\Eri = \\betamkt \\Emkt + \\betahml \\Ehml + \\betaumd \\Eumd\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d1b59",
   "metadata": {},
   "source": [
    "## 1.\n",
    "\n",
    "### (8 pts)\n",
    "\n",
    "Estimate the **time-series (TS)** test of this pricing model. \n",
    "\n",
    "For each asset, report the following statistics:\n",
    "* annualized alpha\n",
    "* betas\n",
    "* r-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfer=pd.read_excel('../data/midterm_2_data.xlsx',sheet_name='factors (excess returns)')\n",
    "dfpor=pd.read_excel('../data/midterm_2_data.xlsx',sheet_name='portfolios (excess returns)')\n",
    "dfrf=pd.read_excel('../data/midterm_2_data.xlsx',sheet_name='risk-free rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta_MKT</th>\n",
       "      <th>beta_HML</th>\n",
       "      <th>beta_UMD</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NoDur</th>\n",
       "      <td>0.029253</td>\n",
       "      <td>0.739522</td>\n",
       "      <td>0.204580</td>\n",
       "      <td>0.049333</td>\n",
       "      <td>0.617919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Durbl</th>\n",
       "      <td>0.010734</td>\n",
       "      <td>1.271865</td>\n",
       "      <td>0.173595</td>\n",
       "      <td>-0.320023</td>\n",
       "      <td>0.613493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Manuf</th>\n",
       "      <td>-0.000996</td>\n",
       "      <td>1.049482</td>\n",
       "      <td>0.197462</td>\n",
       "      <td>-0.036704</td>\n",
       "      <td>0.870268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Enrgy</th>\n",
       "      <td>-0.015117</td>\n",
       "      <td>0.992222</td>\n",
       "      <td>0.637006</td>\n",
       "      <td>0.075170</td>\n",
       "      <td>0.465602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HiTec</th>\n",
       "      <td>0.028207</td>\n",
       "      <td>1.154959</td>\n",
       "      <td>-0.637135</td>\n",
       "      <td>-0.140638</td>\n",
       "      <td>0.829498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telcm</th>\n",
       "      <td>0.003506</td>\n",
       "      <td>0.837326</td>\n",
       "      <td>0.094363</td>\n",
       "      <td>-0.084518</td>\n",
       "      <td>0.588052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shops</th>\n",
       "      <td>0.026739</td>\n",
       "      <td>0.946928</td>\n",
       "      <td>-0.042222</td>\n",
       "      <td>-0.015005</td>\n",
       "      <td>0.742161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hlth</th>\n",
       "      <td>0.031862</td>\n",
       "      <td>0.757605</td>\n",
       "      <td>-0.119928</td>\n",
       "      <td>0.074058</td>\n",
       "      <td>0.580514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utils</th>\n",
       "      <td>0.013710</td>\n",
       "      <td>0.527879</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0.108622</td>\n",
       "      <td>0.342654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>-0.019780</td>\n",
       "      <td>1.115433</td>\n",
       "      <td>0.426753</td>\n",
       "      <td>-0.048678</td>\n",
       "      <td>0.910098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          alpha  beta_MKT  beta_HML  beta_UMD        r2\n",
       "NoDur  0.029253  0.739522  0.204580  0.049333  0.617919\n",
       "Durbl  0.010734  1.271865  0.173595 -0.320023  0.613493\n",
       "Manuf -0.000996  1.049482  0.197462 -0.036704  0.870268\n",
       "Enrgy -0.015117  0.992222  0.637006  0.075170  0.465602\n",
       "HiTec  0.028207  1.154959 -0.637135 -0.140638  0.829498\n",
       "Telcm  0.003506  0.837326  0.094363 -0.084518  0.588052\n",
       "Shops  0.026739  0.946928 -0.042222 -0.015005  0.742161\n",
       "Hlth   0.031862  0.757605 -0.119928  0.074058  0.580514\n",
       "Utils  0.013710  0.527879  0.353033  0.108622  0.342654\n",
       "Other -0.019780  1.115433  0.426753 -0.048678  0.910098"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg=run_regression(dfpor,dfer.iloc[:,1:],12)\n",
    "reg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31da8bdc",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "### (7pts)\n",
    "\n",
    "Estimate the **cross-sectional (CS)** test of the pricing model. \n",
    "\n",
    "Include an intercept in your cross-sectional test.\n",
    "\n",
    "Report the\n",
    "* annualized intercept\n",
    "* annualized regression coefficients\n",
    "* r-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized Intercept 0.06371608035760146\n",
      "Regression coefficients {'MKT': 0.002666035066407337, 'HML': -0.0013138850666785042, 'UMD': 0.0025250435970351035}\n",
      "r2: 0.36619814529491257\n"
     ]
    }
   ],
   "source": [
    "temp_df=pd.DataFrame()\n",
    "model=LinearRegression()\n",
    "model.fit(reg.iloc[:,1:-1], dfpor.iloc[:,1:].mean())\n",
    "print('Annualized Intercept', model.intercept_*12)\n",
    "coefficients = {'MKT': model.coef_[0], 'HML': model.coef_[1], 'UMD': model.coef_[2]}\n",
    "print('Regression coefficients', coefficients)\n",
    "r2 = model.score(reg.iloc[:,1:-1], dfpor.iloc[:,1:].mean())\n",
    "print('r2:', r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43dcd2d",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "Report the annualized factor premia (expected excess returns of the three factors) as implied by each of the TS and CS estimations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MKT    0.083853\n",
       "HML    0.025028\n",
       "UMD    0.061692\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfer.iloc[:,1:].mean()*12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MKT 0.03199242079688804\n",
      "HML -0.015766620800142052\n",
      "UMD 0.030300523164421243\n"
     ]
    }
   ],
   "source": [
    "coefficients = {'MKT': model.coef_[0], 'HML': model.coef_[1], 'UMD': model.coef_[2]}\n",
    "for key, value in coefficients.items():\n",
    "    print(key, value*12)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f7e39",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "Use the r-squared statistics from the TS and CS tests above to assess whether these factors are effective for decomposition and/or pricing.\n",
    "\n",
    "Be specific as to how the r-squared statistics from the TS and CS tests impact your conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average TS r2:  0.6560260105076539\n"
     ]
    }
   ],
   "source": [
    "print(\"Average TS r2: \", reg.mean()['r2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the **time series approach**, we can see that the average r2 is ~0.65, which means that on average the factors would explain about 65% of the variability in the respective portfolios. This would not be a good decomposition model, which makes sense, because it is not meant to be one. Regarding pricing, the r2 gives us no information regarding the effectivenes of the model. The alphas would. Therefore, we cannot assess TS effectiveness from r-squared statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Section r2 =  0.36619814529491257\n"
     ]
    }
   ],
   "source": [
    "print('Cross Section r2 = ', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the **cross sectional approach**, the r2 gives us direct information about how much expected returns' variability the model can explain; alternatively, how good of a pricing model this is. The r2 is low, which means that the model can only explain a limited portion of the portfolios returns and has therefore limited, although existing ability for pricing purposes.\n",
    "\n",
    "Regarging factor decomposition, the r2 does not tell us anything about it, since it is only capturing the effect on **expected returns** and not on portfolios' time dependent behavior (other than expected returns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a9d6f",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "Report the annualized pricing mean absolute error (MAE) implied by each of the TS and CS estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-Series MAE:  0.01799\n"
     ]
    }
   ],
   "source": [
    "print('Time-Series MAE: ', round(np.mean(np.abs(reg.alpha)),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Section Mean Absolute Error: 0.08315265267175573\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(reg.iloc[:,1:-1])\n",
    "y_true = dfpor.iloc[:,1:].mean()*12\n",
    "csmae = mean_absolute_error(y_true, y_pred)\n",
    "print('Cross Section Mean Absolute Error:', csmae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e91b41",
   "metadata": {},
   "source": [
    "## 6.\n",
    "\n",
    "Which asset has the highest premium as implied by the TS estimation? And as implied by the CS estimation? (For the latter, feel free to include the cross-sectional intercept.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Portfolio</th>\n",
       "      <th>Expected Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enrgy</td>\n",
       "      <td>0.008648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.008434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Durbl</td>\n",
       "      <td>0.007604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manuf</td>\n",
       "      <td>0.007557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shops</td>\n",
       "      <td>0.006452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HiTec</td>\n",
       "      <td>0.006019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoDur</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Telcm</td>\n",
       "      <td>0.005613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hlth</td>\n",
       "      <td>0.005425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Utils</td>\n",
       "      <td>0.004983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Portfolio  Expected Return\n",
       "3     Enrgy         0.008648\n",
       "9     Other         0.008434\n",
       "1     Durbl         0.007604\n",
       "2     Manuf         0.007557\n",
       "6     Shops         0.006452\n",
       "4     HiTec         0.006019\n",
       "0     NoDur         0.005848\n",
       "5     Telcm         0.005613\n",
       "7     Hlth          0.005425\n",
       "8     Utils         0.004983"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf=pd.DataFrame()\n",
    "tdf['Portfolio']=dfpor.columns[1:]\n",
    "for j, i in enumerate(dfpor.columns[1:]):\n",
    "    corr=[]\n",
    "    corr.append(reg.iloc[j,1])\n",
    "    corr.append(reg.iloc[j,2])\n",
    "    corr.append(reg.iloc[j,3])\n",
    "    i_=0\n",
    "    for ii in range(3):\n",
    "        i_+=corr[ii]*dfer.iloc[:,1:].mean()[ii]\n",
    "    tdf.loc[j,'Expected Return']=i_\n",
    "tdf.sort_values(by='Expected Return', ascending=False, inplace=True)\n",
    "tdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time-series: \n",
    "\n",
    "Highest: Enrgy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Portfolio</th>\n",
       "      <th>Expected Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HiTec</td>\n",
       "      <td>0.008871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shops</td>\n",
       "      <td>0.007852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manuf</td>\n",
       "      <td>0.007756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hlth</td>\n",
       "      <td>0.007674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Durbl</td>\n",
       "      <td>0.007664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enrgy</td>\n",
       "      <td>0.007308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Telcm</td>\n",
       "      <td>0.007205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NoDur</td>\n",
       "      <td>0.007137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Utils</td>\n",
       "      <td>0.006527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Portfolio  Expected Return\n",
       "4     HiTec         0.008871\n",
       "6     Shops         0.007852\n",
       "2     Manuf         0.007756\n",
       "7     Hlth          0.007674\n",
       "1     Durbl         0.007664\n",
       "9     Other         0.007600\n",
       "3     Enrgy         0.007308\n",
       "5     Telcm         0.007205\n",
       "0     NoDur         0.007137\n",
       "8     Utils         0.006527"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttdf=pd.DataFrame()\n",
    "ttdf['Portfolio']=dfpor.columns[1:]\n",
    "ttdf['Expected Return']=y_pred\n",
    "ttdf.sort_values(by='Expected Return', ascending=False, inplace=True)\n",
    "ttdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross_sectional:\n",
    "\n",
    "Highest: HiTec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8eda25",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d9f9ca",
   "metadata": {},
   "source": [
    "# 3. Additional Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e16122",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Consider the three-factor pricing model above. How can we assess whether all three factors are useful in this pricing model? \n",
    "\n",
    "Specifically, discuss whether the previously estimated regression betas would be informative. If not, what other statistic could we calculate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual beta values would be useful when using the model. To determine if the factors themselves are useful, we could construct a tangency portfolio with the three of them, and see what weights are assigned to each factor.\n",
    "\n",
    "We can also see from the cross sectional approach what the estimated premiums are for each factor (indirectly using betas). If some of them are too small, this limits their significance when using the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917ec2d",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "Suppose we are testing the 3-factor model above, and now we want to allow for time-varying betas.\n",
    "\n",
    "How could we test the model while allowing for this?\n",
    "\n",
    "Be specific about the number of regressions we would run and the nature of these regressions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each time period, we could calculate a time-series beta based on only a subset of the data available (a rolling window, for example). Based on this betas, we could run a cross sectional for each time period, and estimate premiums for each period.\n",
    "\n",
    "In particular, we would run a regression for each period of interes, for each asset (time-series, varying betas), then, for each time period we could also run a cross sectional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ae486",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "State one advantage and one disadvantage of using the CS estimation as opposed to the TS estimation in fitting the LFPM to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantage: \n",
    "\n",
    "We can infer premiums from the data, as opposed to only calculating observed behavior for factor proxies directly. This gives the model additional degrees of freedom that make it a more lenient test for the model.\n",
    "\n",
    "Disadvantage:\n",
    "\n",
    "The fact that the test gives the model additional degrees of freedom, also means that some results may not be realistic, and we could further increase inaccuracies in the model making it even less useful for pricing purposes. For example, some premiums may become negative during the fitting process, when other studies would signal positive premiums."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab345650",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "Suppose we are investing in just the assets included in our data set. We want to implement a momentum strategy.\n",
    "\n",
    "Relative to the momentum strategies we studied, do you expect this strategy would have higher or lower...\n",
    "* mean\n",
    "* volatility\n",
    "\n",
    "Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The selection pool seems greatly reduced. This means that it will be harder to leverage small autocorrelation advantages (if any), and potentially, the turnover for top and bottom performers could be higher if only one asset were selected, for example. The momentum strategy tries to exploit tiny advantages in autocorrelation, which we can scale by selecting multiple assets simultaneously. That would not be an option with such a reduced pool within a realistic timeline. I expect the strategy to perform worse in this dataset, so **lower mean, and higher volatility**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd7b8ee",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bba6573",
   "metadata": {},
   "source": [
    "# 4. Returns Over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce55a1",
   "metadata": {},
   "source": [
    "## 1.\n",
    "\n",
    "If Barnstable’s assumptions hold, (log iid returns, normally distributed,) then in what sense is an investment safer in the long-run? And in what sense is it riskier in the long-run?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is safer in the sense that our estimates of the period-specific expected returns become more accurate, their variability will decrease. However, the variance of the cumulative expected returns will increase, which may translate into a riskier investment.\n",
    "\n",
    "In short, point estimate of long term period-specific returns will improve (safer), while the variance of cumulative returns will increase (riskier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e19f68",
   "metadata": {},
   "source": [
    "## 2. \n",
    "\n",
    "### (10pts)\n",
    "\n",
    "Data \n",
    "* Make use of the `risk-free rate` tab.\n",
    "* Construct the **total** factor returns by adding the risk-free rate to the excess `MKT` and `HML` factor returns.\n",
    "\n",
    "Assumptions\n",
    "* The total returns are lognormally distributed and iid. \n",
    "\n",
    "Report the probability that `MKT` will outperform `HML` over the following 5 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that MKT will outperform HML : 71.07 %\n"
     ]
    }
   ],
   "source": [
    "mdfer=dfer.copy()\n",
    "mdfer['MKT']+=dfrf['RF']\n",
    "mdfer['HML']+=dfrf['RF']\n",
    "mdfer['MKT'] = np.log(1 + mdfer['MKT'])\n",
    "mdfer['HML'] = np.log(1 + mdfer['HML'])\n",
    "mmkt=mdfer['MKT'].mean()*12\n",
    "mhml=mdfer['HML'].mean()*12\n",
    "mdfer['Diff']=mdfer['HML']-mdfer['MKT']\n",
    "print('Probability that MKT will outperform HML :', round(100*prob(mu=mdfer['Diff'].mean()*12,sigma=mdfer['Diff'].std()*(12**(1/2)),h=5),2),'%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deca7ce8",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
