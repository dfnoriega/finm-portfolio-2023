{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b2f936",
   "metadata": {},
   "source": [
    "# Midterm 1\n",
    "\n",
    "## FINM 36700 - 2023\n",
    "\n",
    "### UChicago Financial Mathematics\n",
    "\n",
    "* Mark Hendricks\n",
    "* hendricks@uchicago.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af28e7fd",
   "metadata": {},
   "source": [
    "# Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dd63ff",
   "metadata": {},
   "source": [
    "## Please note the following:\n",
    "\n",
    "Points\n",
    "* The exam is 100 points.\n",
    "* You have 120 minutes to complete the exam.\n",
    "* For every minute late you submit the exam, you will lose one point.\n",
    "Final Exam\n",
    "\n",
    "Submission\n",
    "* You will upload your solution to the `Midterm 1` assignment on Canvas, where you downloaded this. (Be sure to **submit** on Canvas, not just **save** on Canvas.\n",
    "* Your submission should be readable, (the graders can understand your answers,) and it should **include all code used in your analysis in a file format that the code can be executed.** \n",
    "\n",
    "Rules\n",
    "* The exam is open-material, closed-communication.\n",
    "* You do not need to cite material from the course github repo--you are welcome to use the code posted there without citation.\n",
    "\n",
    "Advice\n",
    "* If you find any question to be unclear, state your interpretation and proceed. We will only answer questions of interpretation if there is a typo, error, etc.\n",
    "* The exam will be graded for partial credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1960a3c5",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "**All data files are found in the class github repo, in the `data` folder.**\n",
    "\n",
    "This exam makes use of the following data files:\n",
    "* `midterm_data_1.xlsx`\n",
    "\n",
    "This file has sheets for...\n",
    "* `info` - names of each stock ticker\n",
    "* `excess returns` - weekly excess returns on several stocks\n",
    "* `SPY` - weekly excess returns on SPY\n",
    "\n",
    "Note the data is **weekly** so any annualizations should use `52` weeks in a year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f6568",
   "metadata": {},
   "source": [
    "#### If useful\n",
    "here is code to load in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0674f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, skew\n",
    "from scipy.stats import norm\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sympy import Matrix, init_printing, matrix2numpy, diag\n",
    "from scipy.stats import kurtosis\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (16,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344abdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILEIN = '../data/midterm_1_data.xlsx'\n",
    "sheet_exrets = 'excess returns'\n",
    "sheet_spy = 'spy'\n",
    "\n",
    "retsx = pd.read_excel(FILEIN, sheet_name=sheet_exrets).set_index('date')\n",
    "spy = pd.read_excel(FILEIN, sheet_name=sheet_spy).set_index('date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0af33e1",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "| Problem | Points |\n",
    "|---------|--------|\n",
    "| 1       | 20     |\n",
    "| 2       | 35     |\n",
    "| 3       | 30     |\n",
    "| 4       | 15     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158c236",
   "metadata": {},
   "source": [
    "### Each numbered question is worth 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362090a7",
   "metadata": {},
   "source": [
    "### Notation\n",
    "(Hidden LaTeX commands)\n",
    "\n",
    "$$\\newcommand{\\mux}{\\tilde{\\boldsymbol{\\mu}}}$$\n",
    "$$\\newcommand{\\wtan}{\\boldsymbol{\\text{w}}^{\\text{tan}}}$$\n",
    "$$\\newcommand{\\wtarg}{\\boldsymbol{\\text{w}}^{\\text{port}}}$$\n",
    "$$\\newcommand{\\mutarg}{\\tilde{\\boldsymbol{\\mu}}^{\\text{port}}}$$\n",
    "$$\\newcommand{\\wEW}{\\boldsymbol{\\text{w}}^{\\text{EW}}}$$\n",
    "$$\\newcommand{\\wRP}{\\boldsymbol{\\text{w}}^{\\text{RP}}}$$\n",
    "$$\\newcommand{\\wREG}{\\boldsymbol{\\text{w}}^{\\text{REG}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40926a81",
   "metadata": {},
   "source": [
    "# 1. Short Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c0d60",
   "metadata": {},
   "source": [
    "### No Data Needed\n",
    "\n",
    "These problem does not require any data file. Rather, analyze the situation conceptually, based on the information below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d086f971",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "In what sense was ProShares `HDG` successful in hedging the `HFRI`, and in what sense was it unsuccessful in tracking the `HFRI`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be04c5",
   "metadata": {},
   "source": [
    "It was succesfull in that HDG's correlation with ML Factor's model, which itself tracks the HFRI, was very high. Approximately 99%. However, some of the features of the HFRI were not necessarily appropriately captured. The skewness and kurtosis were not matched as closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ddf91",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "We discussed multiple ways of calculating Value-at-Risk (VaR). What are the tradeoffs between using the normal distribution formula versus a directly empirical approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3b423",
   "metadata": {},
   "source": [
    "The main tradeoff is imposing a statistical model that does not necessarily fit the data in order to gain statistical power. When using the empirical approach, one cosiders only very few (potentially one) observation(s). However, when using the normal distribution formula, we can use the volatility of the dataset as a whole. The empirical approach is in a sense \"overfitting\" bad events in the data. Using the normal distribution sacrifices precision to gain statistical power. In general, the normal distribution approach seems to perform better at predicting VAR threshold despite including some bias in the process while imposing a potentially inaccurate model onto the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8b7e68",
   "metadata": {},
   "source": [
    "## 3\n",
    "\n",
    "Did we find that **TIPS** have been useful in expanding the mean-variance frontier in the past? Did we conclude they might be useful in the future? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec3928",
   "metadata": {},
   "source": [
    "There is more diversification between TIPS and bonds than between SPY and many other equity buckets Harvard has. As an additional security, TIPS was useful in expanding the mean-variance frontier. They can be used in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97348b",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "What aspect of the classic mean-variance optimization approach leads to extreme answers? How did regularization help with this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e143afb2",
   "metadata": {},
   "source": [
    "Because of typically high condition numbers in the covariance matrix, or high sensitivity of its inverse, small variations on expected returns could affect significantly the weights on specific assets. The classic mean-variance optimization approach assumes observed mean returns as certain and concrete values, even though in reality they are hard to estimate extremely accurately. Because of this, the classic mean-variance optimization can take very large positions on specific assets, when in reality potential gains from such positions could be highly uncertain. Regularization prevents precisely such large weights in the final allocation/weights, by penalizing in some form large coefficients. It helps the optimization take observed data \"less seriously\", or consider the fact that it may not perfectly predict future performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e42346",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d66389e",
   "metadata": {},
   "source": [
    "# 2. Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b67603",
   "metadata": {},
   "source": [
    "Consider a mean-variance optimization of **excess** returns provided in `midterm_1_data.xlsx.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe496df",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Report the following **annualized** statistics:\n",
    "* mean\n",
    "* volatility\n",
    "* Sharpe ratio\n",
    "\n",
    "Which assets have the highest / lowest Sharpe ratios?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2526be53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Vol</th>\n",
       "      <th>Sharpe</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Excess Kurtosis</th>\n",
       "      <th>VaR (0.05)</th>\n",
       "      <th>CVaR (0.05)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.319421</td>\n",
       "      <td>0.283883</td>\n",
       "      <td>1.125183</td>\n",
       "      <td>-0.190566</td>\n",
       "      <td>0.143562</td>\n",
       "      <td>-0.334342</td>\n",
       "      <td>2.672198</td>\n",
       "      <td>-0.052313</td>\n",
       "      <td>-0.085612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.288087</td>\n",
       "      <td>0.240206</td>\n",
       "      <td>1.199334</td>\n",
       "      <td>-0.150492</td>\n",
       "      <td>0.104231</td>\n",
       "      <td>-0.359175</td>\n",
       "      <td>1.737189</td>\n",
       "      <td>-0.049366</td>\n",
       "      <td>-0.071559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.239457</td>\n",
       "      <td>0.310389</td>\n",
       "      <td>0.771474</td>\n",
       "      <td>-0.151901</td>\n",
       "      <td>0.156111</td>\n",
       "      <td>-0.210630</td>\n",
       "      <td>1.746315</td>\n",
       "      <td>-0.061868</td>\n",
       "      <td>-0.096065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.650658</td>\n",
       "      <td>0.468096</td>\n",
       "      <td>1.390011</td>\n",
       "      <td>-0.210199</td>\n",
       "      <td>0.332580</td>\n",
       "      <td>0.425676</td>\n",
       "      <td>2.244417</td>\n",
       "      <td>-0.083805</td>\n",
       "      <td>-0.119446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.193328</td>\n",
       "      <td>0.274217</td>\n",
       "      <td>0.705020</td>\n",
       "      <td>-0.135524</td>\n",
       "      <td>0.149258</td>\n",
       "      <td>0.041986</td>\n",
       "      <td>1.143573</td>\n",
       "      <td>-0.055729</td>\n",
       "      <td>-0.078408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.569728</td>\n",
       "      <td>0.607026</td>\n",
       "      <td>0.938556</td>\n",
       "      <td>-0.284957</td>\n",
       "      <td>0.334897</td>\n",
       "      <td>0.441455</td>\n",
       "      <td>1.527376</td>\n",
       "      <td>-0.122519</td>\n",
       "      <td>-0.155313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.124196</td>\n",
       "      <td>0.311613</td>\n",
       "      <td>0.398557</td>\n",
       "      <td>-0.175338</td>\n",
       "      <td>0.184173</td>\n",
       "      <td>0.097936</td>\n",
       "      <td>3.129459</td>\n",
       "      <td>-0.061685</td>\n",
       "      <td>-0.097340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Mean       Vol    Sharpe       Min       Max  Skewness  \\\n",
       "AAPL   0.319421  0.283883  1.125183 -0.190566  0.143562 -0.334342   \n",
       "MSFT   0.288087  0.240206  1.199334 -0.150492  0.104231 -0.359175   \n",
       "AMZN   0.239457  0.310389  0.771474 -0.151901  0.156111 -0.210630   \n",
       "NVDA   0.650658  0.468096  1.390011 -0.210199  0.332580  0.425676   \n",
       "GOOGL  0.193328  0.274217  0.705020 -0.135524  0.149258  0.041986   \n",
       "TSLA   0.569728  0.607026  0.938556 -0.284957  0.334897  0.441455   \n",
       "XOM    0.124196  0.311613  0.398557 -0.175338  0.184173  0.097936   \n",
       "\n",
       "       Excess Kurtosis  VaR (0.05)  CVaR (0.05)  \n",
       "AAPL          2.672198   -0.052313    -0.085612  \n",
       "MSFT          1.737189   -0.049366    -0.071559  \n",
       "AMZN          1.746315   -0.061868    -0.096065  \n",
       "NVDA          2.244417   -0.083805    -0.119446  \n",
       "GOOGL         1.143573   -0.055729    -0.078408  \n",
       "TSLA          1.527376   -0.122519    -0.155313  \n",
       "XOM           3.129459   -0.061685    -0.097340  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summary_statistics_annualized(returns, annual_factor = 52):\n",
    "    \"\"\"This functions returns the summary statistics for the input total/excess returns passed\n",
    "    into the function\"\"\"\n",
    "    \n",
    "    summary_statistics = pd.DataFrame(index=returns.columns)\n",
    "    summary_statistics['Mean'] = returns.mean() * annual_factor\n",
    "    summary_statistics['Vol'] = returns.std() * np.sqrt(annual_factor)\n",
    "    summary_statistics['Sharpe'] = (returns.mean() / returns.std()) * np.sqrt(annual_factor)\n",
    "    summary_statistics['Min'] = returns.min()\n",
    "    summary_statistics['Max'] = returns.max()\n",
    "    summary_statistics['Skewness'] = returns.skew()\n",
    "    summary_statistics['Excess Kurtosis'] = returns.kurtosis()\n",
    "    summary_statistics['VaR (0.05)'] = returns.quantile(.05, axis = 0)\n",
    "    summary_statistics['CVaR (0.05)'] = returns[returns <= returns.quantile(.05, axis = 0)].mean()\n",
    "    \n",
    "    return summary_statistics\n",
    "\n",
    "\n",
    "stats=summary_statistics_annualized(retsx)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f5018",
   "metadata": {},
   "source": [
    "**The data is weekly! I am assuming/using 52 weeks in a year (x52) to annualize the values**\n",
    "\n",
    "Highest Sharpe: NVDA\n",
    "\n",
    "Lowest Sharpe: XOM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f091c84",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "Report the weights of the tangency portfolio.\n",
    "\n",
    "Also report the Sharpe ratio achieved by the tangency portfolio over this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b505594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tangent Weights</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tickers</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.322604866030519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.787495885834573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>-0.228606530386357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.495995507989400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>-0.502721011619707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.105974674197866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.0192566079537055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Tangent Weights\n",
       "tickers                    \n",
       "AAPL      0.322604866030519\n",
       "MSFT      0.787495885834573\n",
       "AMZN     -0.228606530386357\n",
       "NVDA      0.495995507989400\n",
       "GOOGL    -0.502721011619707\n",
       "TSLA      0.105974674197866\n",
       "XOM      0.0192566079537055"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_statistics(df):\n",
    "    res={}\n",
    "    res_i={}\n",
    "    for i in df.columns:\n",
    "        if df[i].dtype=='<M8[ns]':\n",
    "            pass\n",
    "        else:\n",
    "            res_i.update({'mean':np.mean(df[i])*52})\n",
    "            res_i.update({'volatility':np.std(df[i])*(52**(1/2))})\n",
    "            res_i.update({'sharpe':res_i['mean']/res_i['volatility']})\n",
    "            res.update({i:res_i})\n",
    "            res_i={}\n",
    "    return res\n",
    "\n",
    "def calculate_statistics_array(data):\n",
    "    res_i={}\n",
    "    res_i.update({'mean':np.mean(data)*52})\n",
    "    res_i.update({'volatility':np.std(data)*(52**(1/2))})\n",
    "    res_i.update({'sharpe':res_i['mean']/res_i['volatility']})\n",
    "    return res_i\n",
    "\n",
    "\n",
    "def correlation_matrix(df):\n",
    "    return df.corr()\n",
    "\n",
    "#Make sure the first column is dates\n",
    "def tangency_portfolio(df):\n",
    "    stats=calculate_statistics(df)\n",
    "    assets=len(df.columns)\n",
    "    mdf=Matrix(df.cov())\n",
    "    vect1=Matrix([1]*assets)\n",
    "    mean=[]\n",
    "    for i in stats:\n",
    "        mean.append(stats[i]['mean'])\n",
    "    vectmean=Matrix(mean)\n",
    "    sigma_inv=mdf.inv()\n",
    "    wt=(1/((vect1.T@sigma_inv@vectmean)[0,0]))*(sigma_inv@vectmean)\n",
    "\n",
    "    tickers=[]\n",
    "    for i in stats:\n",
    "        tickers.append(i)\n",
    "    tan_port=pd.DataFrame()\n",
    "    tan_port['tickers']=tickers\n",
    "    tan_port['Tangent Weights']=0\n",
    "    for i in range(len(tan_port)):\n",
    "        tan_port.loc[i,'Tangent Weights']=wt[i]\n",
    "    \n",
    "    tan_port.set_index('tickers', inplace=True,drop=True)\n",
    "\n",
    "    return tan_port\n",
    "\n",
    "wt=tangency_portfolio(retsx)\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933837df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 0.5634741093289564, 'volatility': 0.35789342042717837, 'sharpe': 1.5744187435924324}\n",
      "\n",
      "Tangency portfolio's Sharpe:  1.5744187435924324\n"
     ]
    }
   ],
   "source": [
    "stats_tangency=calculate_statistics_array(tangency_portfolio(retsx)['Tangent Weights']@retsx.T)\n",
    "print(stats_tangency)\n",
    "print()\n",
    "print(\"Tangency portfolio's Sharpe: \", stats_tangency['sharpe'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bab65",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "* What weight is given to the asset with the lowest Sharpe ratio?\n",
    "* What Sharpe ratio does the lowest (most negative) weight asset have?\n",
    "\n",
    "Explain. Support your answer with evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e4a14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tangent Weights</th>\n",
       "      <th>Sharpe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.322604866030519</td>\n",
       "      <td>1.125183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.787495885834573</td>\n",
       "      <td>1.199334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>-0.228606530386357</td>\n",
       "      <td>0.771474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.495995507989400</td>\n",
       "      <td>1.390011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>-0.502721011619707</td>\n",
       "      <td>0.705020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.105974674197866</td>\n",
       "      <td>0.938556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.0192566079537055</td>\n",
       "      <td>0.398557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Tangent Weights    Sharpe\n",
       "AAPL    0.322604866030519  1.125183\n",
       "MSFT    0.787495885834573  1.199334\n",
       "AMZN   -0.228606530386357  0.771474\n",
       "NVDA    0.495995507989400  1.390011\n",
       "GOOGL  -0.502721011619707  0.705020\n",
       "TSLA    0.105974674197866  0.938556\n",
       "XOM    0.0192566079537055  0.398557"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twt=wt.copy()\n",
    "twt = twt.merge(stats[['Sharpe']], left_index=True, right_index=True)\n",
    "twt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef74d75",
   "metadata": {},
   "source": [
    "The asset with the lowest sharpe ratio (XOM) gets a weight of 0.019.\n",
    "\n",
    "The asset with the lowest weight (GOOGL) has a sharpe of ~0.705.\n",
    "\n",
    "The weights are highly dependent on the correlation/covariance among available assets, more than on the individual sharpes or individual performances themselves. This effect is accentuated the more assets we consider in the optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131963d5",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "Let's examine the out-of-sample performance.\n",
    "\n",
    "Calculate and report the following three allocations using only data through the end of 2022:\n",
    "* tangency portfolio\n",
    "* equally weighted portfolio\n",
    "* a regularized approach, with a new formula shown below\n",
    "\n",
    "where\n",
    "$$\\wEW_i = \\frac{1}{n}$$\n",
    "\n",
    "$$\\wREG \\sim \\widehat{\\Sigma}^{-1}\\mux$$\n",
    "\n",
    "$$\\widehat{\\Sigma} = \\frac{\\Sigma + \\boldsymbol{2}\\,\\Sigma_D}{\\boldsymbol{3}}$$\n",
    "where $\\Sigma_D$ denotes a *diagonal* matrix of the security variances, with zeros in the off-diagonals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf63bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tangency_portfolio_rfr(asset_return,cov_matrix, cov_diagnolize = False):\n",
    "    \"\"\" \n",
    "        Returns the tangency portfolio weights in a (1 x n) vector\n",
    "        Inputs: \n",
    "            asset_return - return for each asset (n x 1) Vector\n",
    "            cov_matrix = nxn covariance matrix for the assets\n",
    "    \"\"\"\n",
    "    if cov_diagnolize:\n",
    "        asset_cov = np.diag(np.diag(cov_matrix))\n",
    "    else:\n",
    "        asset_cov = np.array(cov_matrix)\n",
    "    inverted_cov= np.linalg.inv(asset_cov)\n",
    "    one_vector = np.ones(len(cov_matrix.index))\n",
    "    \n",
    "    den = (one_vector @ inverted_cov) @ (asset_return)\n",
    "    num =  inverted_cov @ asset_return\n",
    "    return (1/den) * num\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d5fc0",
   "metadata": {},
   "source": [
    "Tangency Portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d823de3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tangency Portfolio Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.310565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>1.073114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>-0.259080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.380133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>-0.751548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.101559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.145257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Tangency Portfolio Weight\n",
       "AAPL                    0.310565\n",
       "MSFT                    1.073114\n",
       "AMZN                   -0.259080\n",
       "NVDA                    0.380133\n",
       "GOOGL                  -0.751548\n",
       "TSLA                    0.101559\n",
       "XOM                     0.145257"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retsx_2022 = retsx.loc[:'2022-12-31'].copy()\n",
    "TangencyPort_df_2022 = pd.DataFrame(tangency_portfolio_rfr(retsx_2022.mean(), retsx_2022.cov()),columns= [\"Tangency Portfolio Weight\"],index=retsx.columns)\n",
    "TangencyPort_df_2022\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df12126",
   "metadata": {},
   "source": [
    "Equally weighted portfolio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66b03613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EW Portfolio Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EW Portfolio Weight\n",
       "AAPL              0.142857\n",
       "MSFT              0.142857\n",
       "AMZN              0.142857\n",
       "NVDA              0.142857\n",
       "GOOGL             0.142857\n",
       "TSLA              0.142857\n",
       "XOM               0.142857"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Equally_weighted = pd.DataFrame(columns= [\"EW Portfolio Weight\"],index=retsx.columns)\n",
    "Equally_weighted[\"EW Portfolio Weight\"] = 1/len(retsx.columns)\n",
    "Equally_weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68abb189",
   "metadata": {},
   "source": [
    "Regularized approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f97959d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reg Portfolio Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>2.175852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>2.715273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.418795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>1.646301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.141063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>0.734261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.779944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Reg Portfolio Weight\n",
       "AAPL               2.175852\n",
       "MSFT               2.715273\n",
       "AMZN               0.418795\n",
       "NVDA               1.646301\n",
       "GOOGL              0.141063\n",
       "TSLA               0.734261\n",
       "XOM                0.779944"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix = retsx.cov()\n",
    "cov_diag = np.diag(np.diag(cov_matrix))\n",
    "cov_matrix_reg = (cov_matrix + 2*cov_diag)/3\n",
    "cov_matrix_reg_inv = np.linalg.inv(cov_matrix_reg)\n",
    "mean_2022 = retsx_2022.mean()\n",
    "reg_weights = cov_matrix_reg_inv @ mean_2022\n",
    "Reg_weights = pd.DataFrame(columns= [\"Reg Portfolio Weight\"],index=retsx.columns)\n",
    "Reg_weights[\"Reg Portfolio Weight\"] = reg_weights\n",
    "Reg_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9255bdd",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "Report the out-of-sample (2023) performance of all three portfolios in terms of annualized mean, vol, and Sharpe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d341be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tangency Portfolio Summary Statistics for 2023:\n",
      " {'mean': 1.204709053182053, 'volatility': 0.43572077841290124, 'sharpe': 2.7648648236840265}\n",
      "Equally Weighted Portfolio Summary Statistics for 2023:\n",
      " {'mean': 0.9551326432690281, 'volatility': 0.24250313271806, 'sharpe': 3.9386404314186256}\n",
      "Regularized Portfolio Summary Statistics for 2023:\n",
      " {'mean': 8.585486903792894, 'volatility': 2.0746505224419893, 'sharpe': 4.138281031393787}\n"
     ]
    }
   ],
   "source": [
    "# Tangency Portfolio\n",
    "tangency_returns_2023 = (TangencyPort_df_2022['Tangency Portfolio Weight'] * retsx.loc['2023']).sum(axis=1)\n",
    "tangency_stats_2023 = calculate_statistics_array(tangency_returns_2023)\n",
    "\n",
    "print(\"Tangency Portfolio Summary Statistics for 2023:\\n\", tangency_stats_2023)\n",
    "\n",
    "# Equally Weighted Portfolio\n",
    "ew_returns_2023 = (Equally_weighted['EW Portfolio Weight'] * retsx.loc['2023']).sum(axis=1)\n",
    "ew_stats_2023 = calculate_statistics_array(ew_returns_2023)\n",
    "\n",
    "print(\"Equally Weighted Portfolio Summary Statistics for 2023:\\n\", ew_stats_2023)\n",
    "\n",
    "# Regularized Portfolio\n",
    "reg_returns_2023 = (Reg_weights['Reg Portfolio Weight'] * retsx.loc['2023']).sum(axis=1)\n",
    "reg_stats_2023 = calculate_statistics_array(reg_returns_2023)\n",
    "\n",
    "print(\"Regularized Portfolio Summary Statistics for 2023:\\n\", reg_stats_2023)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65554c5",
   "metadata": {},
   "source": [
    "## 6.\n",
    "\n",
    "Imagine just for this problem that this data is for **total** returns, not excess returns.\n",
    "\n",
    "Report the weights of the global-minimum-variance portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20f60ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GMV Portfolio Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.206231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSFT</th>\n",
       "      <td>0.491250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>0.160866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NVDA</th>\n",
       "      <td>-0.119168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.011378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSLA</th>\n",
       "      <td>-0.046927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.296369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GMV Portfolio Weight\n",
       "AAPL               0.206231\n",
       "MSFT               0.491250\n",
       "AMZN               0.160866\n",
       "NVDA              -0.119168\n",
       "GOOGL              0.011378\n",
       "TSLA              -0.046927\n",
       "XOM                0.296369"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gmv_portfolio(cov_matrix):\n",
    "    \"\"\" \n",
    "        Returns the Global Minimum Variance portfolio weights in a (1 x n) vector\n",
    "        Inputs: \n",
    "            asset_return - return for each asset (n x 1) Vector\n",
    "            cov_matrix = nxn covariance matrix for the assets\n",
    "    \"\"\"\n",
    "    asset_cov = np.array(cov_matrix)\n",
    "    inverted_cov= np.linalg.inv(asset_cov)\n",
    "    one_vector = np.ones(len(cov_matrix.index))\n",
    "    \n",
    "    den = (one_vector @ inverted_cov) @ (one_vector)\n",
    "    num =  inverted_cov @ one_vector\n",
    "    return (1/den) * num\n",
    "\n",
    "gmv_weights = gmv_portfolio(retsx.cov())\n",
    "gmv_df = pd.DataFrame(gmv_weights, columns=['GMV Portfolio Weight'], index=retsx.columns)\n",
    "gmv_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b41a996",
   "metadata": {},
   "source": [
    "## 7.\n",
    "\n",
    "To target a mean return of 0.005%, would you be long or short this global minimum variance portfolio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7f818a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMV Portfolio Summary Statistics for 2023:\n",
      " {'mean': 0.180652235492206, 'volatility': 0.20264617069916296, 'sharpe': 0.8914663172214198}\n"
     ]
    }
   ],
   "source": [
    "gmv_returns = (gmv_df['GMV Portfolio Weight'] * retsx).sum(axis=1)\n",
    "gmv_stats = calculate_statistics_array(gmv_returns)\n",
    "\n",
    "print(\"GMV Portfolio Summary Statistics for 2023:\\n\", gmv_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede80da",
   "metadata": {},
   "source": [
    "Assuming there is a rf asset, this portfolio would not be involved, as the optimal option would be a combination of the rf asset and the tangency portolio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a93234",
   "metadata": {},
   "source": [
    "However, assuming that there is no rf asset and that the 0.005% return is not annualized:\n",
    "\n",
    "Also, using the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "958ec15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003474081451773192"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmv_stats['mean']/52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5fb3867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010836040564018391"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_tangency['mean']/52"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1ea86a",
   "metadata": {},
   "source": [
    "You would be long! The mean is in-between the minimim variance and the tangency portfolio so no need to short."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cdbfa9",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d9fbd",
   "metadata": {},
   "source": [
    "# 3. Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426af123",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Report the following performance metrics of excess returns for Tesla (`TSLA`).\n",
    "* skewness\n",
    "* kurtosis\n",
    "\n",
    "You are not annualizing any of these stats.\n",
    "\n",
    "What do these metrics indicate about the nature of the returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "563b4cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness:  0.44145458268186166\n",
      "Kurtosis:  1.5273762473269983\n"
     ]
    }
   ],
   "source": [
    "def performance_summary(return_data, annualization = 52):\n",
    "    \"\"\" \n",
    "        Returns the Performance Stats for given set of returns\n",
    "        Inputs: \n",
    "            return_data - DataFrame with Date index and Monthly Returns for different assets/strategies.\n",
    "        Output:\n",
    "            summary_stats - DataFrame with annualized mean return, vol, sharpe ratio. Skewness, Excess Kurtosis, Var (0.5) and\n",
    "                            CVaR (0.5) and drawdown based on monthly returns. \n",
    "    \"\"\"\n",
    "    summary_stats = return_data.mean().to_frame('Mean').apply(lambda x: x*annualization)\n",
    "    summary_stats['Volatility'] = return_data.std().apply(lambda x: x*np.sqrt(annualization))\n",
    "    summary_stats['Sharpe Ratio'] = summary_stats['Mean']/summary_stats['Volatility']\n",
    "\n",
    "    summary_stats['Skewness'] = return_data.skew()\n",
    "    summary_stats['Excess Kurtosis'] = return_data.kurtosis()\n",
    "    summary_stats['VaR (0.05)'] = return_data.quantile(.05, axis = 0)\n",
    "    summary_stats['CVaR (0.05)'] = return_data[return_data <= return_data.quantile(.05, axis = 0)].mean()\n",
    "    \n",
    "    wealth_index = 1000*(1+return_data).cumprod()\n",
    "    previous_peaks = wealth_index.cummax()\n",
    "    drawdowns = (wealth_index - previous_peaks)/previous_peaks\n",
    "\n",
    "    summary_stats['Max Drawdown'] = drawdowns.min()\n",
    "    summary_stats['Peak'] = [previous_peaks[col][:drawdowns[col].idxmin()].idxmax() for col in previous_peaks.columns]\n",
    "    summary_stats['Bottom'] = drawdowns.idxmin()\n",
    "    \n",
    "    recovery_date = []\n",
    "    for col in wealth_index.columns:\n",
    "        prev_max = previous_peaks[col][:drawdowns[col].idxmin()].max()\n",
    "        recovery_wealth = pd.DataFrame([wealth_index[col][drawdowns[col].idxmin():]]).T\n",
    "        recovery_date.append(recovery_wealth[recovery_wealth[col] >= prev_max].index.min())\n",
    "    summary_stats['Recovery'] = recovery_date\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "perf_metrics=performance_summary(retsx).loc['TSLA']\n",
    "\n",
    "\n",
    "print('Skewness: ', perf_metrics['Skewness'])\n",
    "print('Kurtosis: ', perf_metrics['Excess Kurtosis'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8f791",
   "metadata": {},
   "source": [
    "Positive skewness in a dataset indicates that the data is skewed or biased towards the right side of the distribution. In other words, the tail on the right side of the distribution is longer or fatter than the left side. \n",
    "\n",
    "Excess kurtosis is a measure of the shape of a probability distribution, specifically focusing on the tails of the distribution. Positive excess kurtosis indicates that the distribution has fatter or heavier tails compared to a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877253fc",
   "metadata": {},
   "source": [
    "## 2. \n",
    "\n",
    "Report the maximum drawdown for `TSLA` over the sample.\n",
    "* Ignore that your data is in excess returns rather than total returns.\n",
    "* Simply proceed with the excess return data for this calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88807620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Drawdown:  -0.6821852296331565\n",
      "Peak:  2021-11-05 00:00:00\n",
      "Bottom:  2023-01-06 00:00:00\n",
      "Recovery:  NaT\n"
     ]
    }
   ],
   "source": [
    "print('Max Drawdown: ',perf_metrics['Max Drawdown'])\n",
    "print('Peak: ',perf_metrics['Peak'])\n",
    "print('Bottom: ',perf_metrics['Bottom'])\n",
    "print('Recovery: ',perf_metrics['Recovery'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d77a74",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "For `TSLA`, calculate the following metrics, relative to `SPY`:\n",
    "* market beta\n",
    "* alpha\n",
    "* sortino ratio\n",
    "\n",
    "Annualize alpha and sortino ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9c48825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_based_performance(factor,fund_ret,rf,constant = True):\n",
    "    \"\"\" \n",
    "        Returns the Regression based performance Stats for given set of returns and factors\n",
    "        Inputs:\n",
    "            factor - Dataframe containing monthly returns of the regressors\n",
    "            fund_ret - Dataframe containing monthly excess returns of the regressand fund\n",
    "            rf - Monthly risk free rate of return\n",
    "        Output:\n",
    "            summary_stats - (Beta of regression, treynor ratio, information ratio, alpha). \n",
    "    \"\"\"\n",
    "    if constant:\n",
    "        X = sm.tools.add_constant(factor)\n",
    "    else:\n",
    "        X = factor\n",
    "    y=fund_ret\n",
    "    model = sm.OLS(y,X,missing='drop').fit()\n",
    "    \n",
    "    if constant:\n",
    "        beta = model.params[1:]\n",
    "        alpha = round(float(model.params['const']),6)\n",
    "        \n",
    "    else:\n",
    "        beta = model.params\n",
    "    treynor_ratio = ((fund_ret.values-rf.values).mean()*12)/beta[0]\n",
    "    tracking_error = (model.resid.std()*np.sqrt(12))\n",
    "    if constant:        \n",
    "        information_ratio = model.params[0]*12/tracking_error\n",
    "    r_squared = model.rsquared\n",
    "    if constant:\n",
    "        return (beta,treynor_ratio,information_ratio,alpha,r_squared,tracking_error,alpha)\n",
    "    else:\n",
    "        return (beta,treynor_ratio,r_squared,tracking_error,alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0dacbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Beta for TSLA:  SPY    1.776825\n",
      "dtype: float64\n",
      "Alpha for TSLA:  0.36142897135532337\n",
      "Sortino Ratio for TSLA:  0.4512712557740471\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# calculate market beta, alpha and sortino ratio\n",
    "\n",
    "rf = pd.Series(np.zeros(len(retsx)), index=retsx.index) # create a series of zeros with the same length as retsx\n",
    "\n",
    "res = regression_based_performance(spy, retsx['TSLA'], rf=rf)\n",
    "alpha=res[-1]\n",
    "beta=res[0]\n",
    "\n",
    "alpha_annual = (1 + alpha) ** 52 - 1\n",
    "\n",
    "# print results\n",
    "print(\"Market Beta for TSLA: \", beta)\n",
    "print(\"Alpha for TSLA: \", alpha_annual)\n",
    "\n",
    "def sortino_ratio(returns, rf=0, target=0):\n",
    "    \"\"\"\n",
    "    Calculate Sortino Ratio for a given set of returns\n",
    "    \"\"\"\n",
    "    downside_returns = returns.copy()\n",
    "    downside_returns[returns >= target] = 0\n",
    "    downside_deviation = np.sqrt((downside_returns ** 2).sum() / len(returns)) * np.sqrt(12)\n",
    "    sortino_ratio = (returns.mean() - rf) / downside_deviation\n",
    "    return sortino_ratio\n",
    "\n",
    "sortino = sortino_ratio(retsx['TSLA'] - rf, target=0)\n",
    "print(\"Sortino Ratio for TSLA: \", sortino*np.sqrt(52))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7919b2",
   "metadata": {},
   "source": [
    "## 4.\n",
    "\n",
    "Continuing with `TSLA`, calculate the full-sample, 5th-percentile CVaR.\n",
    "* Use the `normal` formula, assuming mean returns are zero.\n",
    "* Use the full-sample volatility.\n",
    "\n",
    "Use the entire sample to calculate a single CVaR number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8dfce343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full-sample 5th percentile CVaR:  -0.2385757255683332\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# calculate z-score for 5th percentile\n",
    "z = stats.norm.ppf(0.05)\n",
    "\n",
    "# calculate mean and standard deviation of excess returns\n",
    "mean = retsx['TSLA'].mean()\n",
    "std = retsx['TSLA'].std()\n",
    "\n",
    "# calculate CVaR using normal formula\n",
    "cvar = - norm.pdf(z) / 0.05 * std\n",
    "\n",
    "print(\"Full-sample 5th percentile CVaR: \", retsx['TSLA'][retsx['TSLA'] <= cvar].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94065e1d",
   "metadata": {},
   "source": [
    "## 5.\n",
    "\n",
    "Now calculate the 5th-percentile, one-period ahead, **VaR** for `TSLA`.\n",
    "\n",
    "Here, calculate the running series of VaR estimates.\n",
    "\n",
    "Again, \n",
    "* use the normal formula, with mean zero.\n",
    "\n",
    "But now, use the rolling volatility, based on \n",
    "* rolling window or $m=52$ weeks.\n",
    "\n",
    "Report the final 5 values of your calculated VaR series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30dcdced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2023-06-16    1.133727\n",
      "2023-06-23    1.117533\n",
      "2023-06-30    1.104626\n",
      "2023-07-07    1.092999\n",
      "2023-07-14    1.088110\n",
      "Name: TSLA, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "window = 52\n",
    "volatility = retsx['TSLA'].rolling(window).std() * np.sqrt(window)\n",
    "var = -volatility * stats.norm.ppf(0.05)\n",
    "\n",
    "print(var.tail(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a30cac",
   "metadata": {},
   "source": [
    "## 6. \n",
    "\n",
    "Calculate the out-of-sample **hit ratio** for your VaR series reported in your previous answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efee2bb2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3820d1b",
   "metadata": {},
   "source": [
    "# 4. Hedging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b559f9a9",
   "metadata": {},
   "source": [
    "## 1. \n",
    "\n",
    "Consider the following scenario: you are holding a \\$100 million long position in `NVDA`. You wish to hedge the position using some combination of \n",
    "* `AAPL`\n",
    "* `AMZN`\n",
    "* `GOOGL`\n",
    "* `MSFT`\n",
    "\n",
    "Report the positions you would hold of those 4 securities for an optimal hedge.\n",
    "\n",
    "Note:\n",
    "* In the regression estimation, include an intercept.\n",
    "* Use the full-sample regression. No need to worry about in-sample versus out-of-sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5fb6f",
   "metadata": {},
   "source": [
    "The positions of each asset would be the negative of the betas of the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2a323c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    0.005264\n",
      "AAPL     0.341686\n",
      "AMZN     0.417260\n",
      "GOOGL   -0.007848\n",
      "MSFT     0.587897\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# create a dataframe with the selected stocks\n",
    "df = pd.concat([retsx['AAPL'], retsx['AMZN'], retsx['GOOGL'], retsx['MSFT']], axis=1)\n",
    "\n",
    "# add a constant column to the dataframe\n",
    "df = sm.add_constant(df)\n",
    "\n",
    "# run the regression\n",
    "model = sm.OLS(retsx['NVDA'], df).fit()\n",
    "\n",
    "# print the betas\n",
    "print(model.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64317f",
   "metadata": {},
   "source": [
    "The positions in million for a 100 million NVDA long position below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c65f67d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL     34.168649\n",
       "AMZN     41.725986\n",
       "GOOGL    -0.784795\n",
       "MSFT     58.789673\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params[1:]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6127f366",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "How well does the hedge do? Cite a regression statistic to support your answer.\n",
    "\n",
    "Also estimate the volatility of the basis, (epsilon.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a148bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volatility of residuals:  0.047782087688036136\n"
     ]
    }
   ],
   "source": [
    "residuals = retsx['NVDA'] - model.predict(df)\n",
    "residual_volatility = residuals.std()\n",
    "print(\"Volatility of residuals: \", residual_volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7dc71f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared of the regression:  0.45816823611553836\n"
     ]
    }
   ],
   "source": [
    "print(\"R-squared of the regression: \", model.rsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bea94c",
   "metadata": {},
   "source": [
    "An R² value of 0.46 indicates that approximately 46% of the variability in the dependent variable is explained/captured by the assets we are using to hedge.\n",
    "\n",
    "The assets used are not capturing most of the variability seen in NVDA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b6394",
   "metadata": {},
   "source": [
    "## 3.\n",
    "\n",
    "Report the annualized intercept. By including this intercept, what are you assuming about the nature of the returns of `NVDA` as well as the returns of the hedging instruments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8e092c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annualized intercept:  0.31394506967436286\n"
     ]
    }
   ],
   "source": [
    "intercept = model.params['const']\n",
    "intercept_annual = (1 + intercept) ** 52 - 1\n",
    "print(\"Annualized intercept: \", intercept_annual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9c90b",
   "metadata": {},
   "source": [
    "We are assuming that the differences in levels of the returns observed are not necessarily likely to persist in the future, so we want the betas to focus on the variability, as opposed to the difference in the levels themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3b8c7c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
